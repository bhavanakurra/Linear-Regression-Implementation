{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 2\n",
    "* CSCI-4930/5930 ML Fall 2021  (Be sure to discard which section you are not enrolled)\n",
    "* Author: Bhavana Kurra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's load the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# First load the dataset into pandas dataframe\n",
    "full_dataset = pd.read_csv('dataset/baby-weights-dataset.csv',delimiter=',')\n",
    "judge_dataset = pd.read_csv('dataset/judge-without-labels.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks for everyone (Tasks 1-17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1: \n",
    "Separate the full_dataset into two parts: X and y, where X denotes the input matrix containing only the input (i.e., independent explanatory) variables, and y denotes the target variable containing only the target values for exactly the same number of samples in the given full_dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "X = full_dataset.iloc[:,:-1]\n",
    "Y = full_dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         4.3750\n",
      "1         6.9375\n",
      "2         8.5000\n",
      "3         8.5000\n",
      "4         9.0000\n",
      "           ...  \n",
      "101395    9.1250\n",
      "101396    7.3750\n",
      "101397    7.5000\n",
      "101398    7.6250\n",
      "101399    6.2500\n",
      "Name: BWEIGHT, Length: 101400, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2:\n",
    "* Given X representing the input matrix from the full_dataset, y being the target vector (the rightmost column of the full_dataset), obtained from Task 1: \n",
    "* randomly split the (X,y) dataset into 75% for training and 25% for testing using the library function from the library [sklearn.model_selection](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) . Please pass to the train_test_split function an additional argument random_state=45931.\n",
    "* Store the 4 splits as X_train, X_test, y_train, y_test respectively.\n",
    "* Save the ID column for X_train and X_test into ID_train and ID_test as list variable.\n",
    "* Now, drop the ID columns from both X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "#splitting into Xtrain, X_test, y_train, y_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=45931)\n",
    "\n",
    "\n",
    "#Saving the ID column for X_train and X_test into ID_train and ID_test as list variable\n",
    "ID_train = X_train.iloc[:,1].to_frame()\n",
    "ID_test = X_test.iloc[:,1].to_frame()\n",
    "\n",
    "\n",
    "#dropping the ID columns from both X_train and X_test\n",
    "X_train = X_train.drop('ID', axis=1)\n",
    "X_test = X_test.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 76050 entries, 16961 to 28789\n",
      "Data columns (total 35 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   SEX       76050 non-null  int64  \n",
      " 1   MARITAL   76050 non-null  int64  \n",
      " 2   FAGE      76050 non-null  int64  \n",
      " 3   GAINED    76049 non-null  float64\n",
      " 4   VISITS    76050 non-null  int64  \n",
      " 5   MAGE      76050 non-null  int64  \n",
      " 6   FEDUC     76049 non-null  float64\n",
      " 7   MEDUC     76050 non-null  int64  \n",
      " 8   TOTALP    76050 non-null  int64  \n",
      " 9   BDEAD     76050 non-null  int64  \n",
      " 10  TERMS     76050 non-null  int64  \n",
      " 11  LOUTCOME  76050 non-null  int64  \n",
      " 12  WEEKS     76049 non-null  float64\n",
      " 13  RACEMOM   76050 non-null  int64  \n",
      " 14  RACEDAD   76050 non-null  int64  \n",
      " 15  HISPMOM   76050 non-null  object \n",
      " 16  HISPDAD   76050 non-null  object \n",
      " 17  CIGNUM    76049 non-null  float64\n",
      " 18  DRINKNUM  76050 non-null  int64  \n",
      " 19  ANEMIA    76050 non-null  int64  \n",
      " 20  CARDIAC   76050 non-null  int64  \n",
      " 21  ACLUNG    76050 non-null  int64  \n",
      " 22  DIABETES  76050 non-null  int64  \n",
      " 23  HERPES    76050 non-null  int64  \n",
      " 24  HYDRAM    76049 non-null  float64\n",
      " 25  HEMOGLOB  76050 non-null  int64  \n",
      " 26  HYPERCH   76050 non-null  int64  \n",
      " 27  HYPERPR   76050 non-null  int64  \n",
      " 28  ECLAMP    76050 non-null  int64  \n",
      " 29  CERVIX    76050 non-null  int64  \n",
      " 30  PINFANT   76050 non-null  int64  \n",
      " 31  PRETERM   76050 non-null  int64  \n",
      " 32  RENAL     76050 non-null  int64  \n",
      " 33  RHSEN     76050 non-null  int64  \n",
      " 34  UTERINE   76050 non-null  int64  \n",
      "dtypes: float64(5), int64(28), object(2)\n",
      "memory usage: 20.9+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25350 entries, 40925 to 85343\n",
      "Data columns (total 35 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   SEX       25350 non-null  int64  \n",
      " 1   MARITAL   25350 non-null  int64  \n",
      " 2   FAGE      25350 non-null  int64  \n",
      " 3   GAINED    25350 non-null  float64\n",
      " 4   VISITS    25350 non-null  int64  \n",
      " 5   MAGE      25350 non-null  int64  \n",
      " 6   FEDUC     25350 non-null  float64\n",
      " 7   MEDUC     25350 non-null  int64  \n",
      " 8   TOTALP    25350 non-null  int64  \n",
      " 9   BDEAD     25350 non-null  int64  \n",
      " 10  TERMS     25350 non-null  int64  \n",
      " 11  LOUTCOME  25350 non-null  int64  \n",
      " 12  WEEKS     25350 non-null  float64\n",
      " 13  RACEMOM   25350 non-null  int64  \n",
      " 14  RACEDAD   25350 non-null  int64  \n",
      " 15  HISPMOM   25350 non-null  object \n",
      " 16  HISPDAD   25350 non-null  object \n",
      " 17  CIGNUM    25350 non-null  float64\n",
      " 18  DRINKNUM  25350 non-null  int64  \n",
      " 19  ANEMIA    25350 non-null  int64  \n",
      " 20  CARDIAC   25350 non-null  int64  \n",
      " 21  ACLUNG    25350 non-null  int64  \n",
      " 22  DIABETES  25350 non-null  int64  \n",
      " 23  HERPES    25350 non-null  int64  \n",
      " 24  HYDRAM    25350 non-null  float64\n",
      " 25  HEMOGLOB  25350 non-null  int64  \n",
      " 26  HYPERCH   25350 non-null  int64  \n",
      " 27  HYPERPR   25350 non-null  int64  \n",
      " 28  ECLAMP    25350 non-null  int64  \n",
      " 29  CERVIX    25350 non-null  int64  \n",
      " 30  PINFANT   25350 non-null  int64  \n",
      " 31  PRETERM   25350 non-null  int64  \n",
      " 32  RENAL     25350 non-null  int64  \n",
      " 33  RHSEN     25350 non-null  int64  \n",
      " 34  UTERINE   25350 non-null  int64  \n",
      "dtypes: float64(5), int64(28), object(2)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3:\n",
    "Compute mean, stdev, min, max, 25% percentile, median and 75% percentile of BWEIGHT target variable (i.e, the target y) in the training set (i.e., y_train), and print the computed values as a numpy array containing these 7 results (respectively).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of BWEIGHT :  7.256997863247864\n",
      "Standard Deviation of BWEIGHT :  1.3300584336292791\n",
      "Minimum of BWEIGHT :  0.3125\n",
      "Maximum of BWEIGHT :  13.0625\n",
      "25% of BWEIGHT :  6.625\n",
      "Median of BWEIGHT :  7.375\n",
      "75% of BWEIGHT :  8.0625\n"
     ]
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "print('Mean of BWEIGHT : ',y_train.to_frame()['BWEIGHT'].mean())\n",
    "print('Standard Deviation of BWEIGHT : ',y_train.to_frame()['BWEIGHT'].std())\n",
    "print('Minimum of BWEIGHT : ',y_train.to_frame()['BWEIGHT'].min())\n",
    "print('Maximum of BWEIGHT : ',y_train.to_frame()['BWEIGHT'].max())\n",
    "print('25% of BWEIGHT : ',y_train.to_frame()['BWEIGHT'].quantile(0.25))\n",
    "print('Median of BWEIGHT : ',y_train.to_frame()['BWEIGHT'].median())\n",
    "print('75% of BWEIGHT : ',y_train.to_frame()['BWEIGHT'].quantile(0.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 4: \n",
    "Given the training dataset (X_train, y_train), save as X_train_ohe after replacing all the non-numeric variables (i.e., categorical variables) with numeric encoding. Please consider using the \"One-hot encoding\" scheme i.e., introducing dummy variables. A brief description of the scheme can be found in the [DUMMY-variables.note.txt](DUMMY-variables.note.txt) file\n",
    "* Use the same encoder to perform onehotencoding on the X_test dataset and save the result as X_test_ohe.\n",
    "* Print the column names of X_test_ohe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check once????????????????????????????\n",
    "# Categorical boolean mask\n",
    "categorical_feature_mask = X_train.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = X_train.columns[categorical_feature_mask].tolist()\n",
    "cat_columns_idx = [X_train.columns.get_loc(col) \n",
    "                   for col in categorical_cols]#add empty columns like HIPSMOM_N, HIPSMOM_M etc\n",
    "\n",
    "\n",
    "#X_train_ohe\n",
    "#replacing 'HISPMOM', 'HISPDAD' with numerical values, introducing dummy variables\n",
    "#Advice: Don't replace them with numbers!!!\n",
    "#Advice: Add dummy variables for each categories.\n",
    "#X_test_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use when different features need different preprocessing\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "column_trans = make_column_transformer(\n",
    "    (OneHotEncoder(), categorical_cols),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ohe = pd.DataFrame(column_trans.fit_transform(X_train),columns=column_trans.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ohe = pd.DataFrame(column_trans.transform(X_test),columns=column_trans.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['onehotencoder__x0_C', 'onehotencoder__x0_M', 'onehotencoder__x0_N',\n",
       "       'onehotencoder__x0_O', 'onehotencoder__x0_P', 'onehotencoder__x0_S',\n",
       "       'onehotencoder__x0_U', 'onehotencoder__x1_C', 'onehotencoder__x1_M',\n",
       "       'onehotencoder__x1_N', 'onehotencoder__x1_O', 'onehotencoder__x1_P',\n",
       "       'onehotencoder__x1_S', 'onehotencoder__x1_U', 'SEX', 'MARITAL', 'FAGE',\n",
       "       'GAINED', 'VISITS', 'MAGE', 'FEDUC', 'MEDUC', 'TOTALP', 'BDEAD',\n",
       "       'TERMS', 'LOUTCOME', 'WEEKS', 'RACEMOM', 'RACEDAD', 'CIGNUM',\n",
       "       'DRINKNUM', 'ANEMIA', 'CARDIAC', 'ACLUNG', 'DIABETES', 'HERPES',\n",
       "       'HYDRAM', 'HEMOGLOB', 'HYPERCH', 'HYPERPR', 'ECLAMP', 'CERVIX',\n",
       "       'PINFANT', 'PRETERM', 'RENAL', 'RHSEN', 'UTERINE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "X_train_ohe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 5: \n",
    "* Given the X_train_ohe (Onehot encoded Pandas Dataframe from Task 4), check if there are missing values, and if yes, count how many, and impute the missing values with corresponding mean values. \n",
    "* Finally, print the counting result as a Pandas dataframe named \"missing_counts\" having 2 columns {variable_name,num_of_missing_values).  Please make sure that the result lists all the input variables in the given dataset. \n",
    "* Now, impute the missing values by mean of the respective variable and save the revised dataframe as X_train_ohe_imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing count dataframe : \n",
      "          variable_name  num_of_missing_values\n",
      "0   onehotencoder__x0_C                      0\n",
      "1   onehotencoder__x0_M                      0\n",
      "2   onehotencoder__x0_N                      0\n",
      "3   onehotencoder__x0_O                      0\n",
      "4   onehotencoder__x0_P                      0\n",
      "5   onehotencoder__x0_S                      0\n",
      "6   onehotencoder__x0_U                      0\n",
      "7   onehotencoder__x1_C                      0\n",
      "8   onehotencoder__x1_M                      0\n",
      "9   onehotencoder__x1_N                      0\n",
      "10  onehotencoder__x1_O                      0\n",
      "11  onehotencoder__x1_P                      0\n",
      "12  onehotencoder__x1_S                      0\n",
      "13  onehotencoder__x1_U                      0\n",
      "14                  SEX                      0\n",
      "15              MARITAL                      0\n",
      "16                 FAGE                      0\n",
      "17               GAINED                      1\n",
      "18               VISITS                      0\n",
      "19                 MAGE                      0\n",
      "20                FEDUC                      1\n",
      "21                MEDUC                      0\n",
      "22               TOTALP                      0\n",
      "23                BDEAD                      0\n",
      "24                TERMS                      0\n",
      "25             LOUTCOME                      0\n",
      "26                WEEKS                      1\n",
      "27              RACEMOM                      0\n",
      "28              RACEDAD                      0\n",
      "29               CIGNUM                      1\n",
      "30             DRINKNUM                      0\n",
      "31               ANEMIA                      0\n",
      "32              CARDIAC                      0\n",
      "33               ACLUNG                      0\n",
      "34             DIABETES                      0\n",
      "35               HERPES                      0\n",
      "36               HYDRAM                      1\n",
      "37             HEMOGLOB                      0\n",
      "38              HYPERCH                      0\n",
      "39              HYPERPR                      0\n",
      "40               ECLAMP                      0\n",
      "41               CERVIX                      0\n",
      "42              PINFANT                      0\n",
      "43              PRETERM                      0\n",
      "44                RENAL                      0\n",
      "45                RHSEN                      0\n",
      "46              UTERINE                      0\n",
      "\n",
      "X_train_ohe_imputed dataframe : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "onehotencoder__x0_C    0\n",
       "onehotencoder__x0_M    0\n",
       "onehotencoder__x0_N    0\n",
       "onehotencoder__x0_O    0\n",
       "onehotencoder__x0_P    0\n",
       "onehotencoder__x0_S    0\n",
       "onehotencoder__x0_U    0\n",
       "onehotencoder__x1_C    0\n",
       "onehotencoder__x1_M    0\n",
       "onehotencoder__x1_N    0\n",
       "onehotencoder__x1_O    0\n",
       "onehotencoder__x1_P    0\n",
       "onehotencoder__x1_S    0\n",
       "onehotencoder__x1_U    0\n",
       "SEX                    0\n",
       "MARITAL                0\n",
       "FAGE                   0\n",
       "GAINED                 0\n",
       "VISITS                 0\n",
       "MAGE                   0\n",
       "FEDUC                  0\n",
       "MEDUC                  0\n",
       "TOTALP                 0\n",
       "BDEAD                  0\n",
       "TERMS                  0\n",
       "LOUTCOME               0\n",
       "WEEKS                  0\n",
       "RACEMOM                0\n",
       "RACEDAD                0\n",
       "CIGNUM                 0\n",
       "DRINKNUM               0\n",
       "ANEMIA                 0\n",
       "CARDIAC                0\n",
       "ACLUNG                 0\n",
       "DIABETES               0\n",
       "HERPES                 0\n",
       "HYDRAM                 0\n",
       "HEMOGLOB               0\n",
       "HYPERCH                0\n",
       "HYPERPR                0\n",
       "ECLAMP                 0\n",
       "CERVIX                 0\n",
       "PINFANT                0\n",
       "PRETERM                0\n",
       "RENAL                  0\n",
       "RHSEN                  0\n",
       "UTERINE                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "variable_name_list = []\n",
    "num_of_missing_values_list = []\n",
    "for i in X_train_ohe.columns:\n",
    "    variable_name_list.append(i)\n",
    "    num_of_missing_values_list.append(X_train_ohe[i].isna().sum())\n",
    "    \n",
    "\n",
    "missing_counts_dict = {'variable_name':variable_name_list, 'num_of_missing_values':num_of_missing_values_list}\n",
    "missing_count = pd.DataFrame(missing_counts_dict)\n",
    "#missing_count.info()\n",
    "\n",
    "print('missing count dataframe : ')\n",
    "print(missing_count.head(47))\n",
    "\n",
    "\n",
    "X_train_ohe_imputed  = X_train_ohe.copy()\n",
    "for i in X_train_ohe_imputed.columns:\n",
    "    values = X_train_ohe_imputed[i].mean()\n",
    "    X_train_ohe_imputed[i].fillna(value=values, inplace=True)\n",
    "    \n",
    "print('')\n",
    "print('X_train_ohe_imputed dataframe : ')\n",
    "X_train_ohe_imputed.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 6: \n",
    "* Given a X_train_ohe_imputed (Pandas dataframe from Task 5) where all the categorical variables are already replaced with numeric values, print a list of top 20 highly correlated variables with respect to the target variable, and save the result as a Pandas dataframe named top20_df with 2 columns {variable,corr_score}. \n",
    "* Here, the corr_score between a variable x and the target variable y needs to be computed using the Pearson Correlation Coefficient (PCC). Please note, PCC ranges between -1 to +1. PCC score 0 means no correlation, while value towards +1 and -1 represent positive and negative correlations respectively. For instance, PCC=0.8 and PCC=-0.8 tell similar strength positive and negative correlations between the two subject variables.\n",
    "* Please do not include BWEIGHT in the top20_df list of top 20 correlated variable list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 47 entries, 26 to 10\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   variable    47 non-null     object \n",
      " 1   corr_score  47 non-null     float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 1.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>corr_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>WEEKS</td>\n",
       "      <td>0.565254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GAINED</td>\n",
       "      <td>0.174466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>VISITS</td>\n",
       "      <td>0.129247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>HYPERPR</td>\n",
       "      <td>-0.111375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MARITAL</td>\n",
       "      <td>-0.106297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variable  corr_score\n",
       "26    WEEKS    0.565254\n",
       "17   GAINED    0.174466\n",
       "18   VISITS    0.129247\n",
       "39  HYPERPR   -0.111375\n",
       "15  MARITAL   -0.106297"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "variable_list = []\n",
    "corr_score_list = []\n",
    "\n",
    "#deriving correlation for each variable\n",
    "for i in X_train_ohe_imputed.columns:\n",
    "    variable_list.append(i)\n",
    "    corr, _ = pearsonr(X_train_ohe_imputed[i], y_train)\n",
    "    corr_score_list.append(corr)    \n",
    "    \n",
    "\n",
    "top_df_dic = {'variable':variable_list, 'corr_score':corr_score_list}\n",
    "top20_df_tmp = pd.DataFrame(top_df_dic)\n",
    "top20_df_tmp['Absolute_corr_score'] = abs(top20_df_tmp['corr_score'])\n",
    "top20_df_tmp.sort_values(by=['Absolute_corr_score'], ascending=False, inplace=True)\n",
    "top20_df_tmp.drop(['Absolute_corr_score'], axis=1, inplace=True )\n",
    "\n",
    "top20_df_tmp.info()\n",
    "top20_df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76050 entries, 0 to 76049\n",
      "Data columns (total 47 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   onehotencoder__x0_C  76050 non-null  float64\n",
      " 1   onehotencoder__x0_M  76050 non-null  float64\n",
      " 2   onehotencoder__x0_N  76050 non-null  float64\n",
      " 3   onehotencoder__x0_O  76050 non-null  float64\n",
      " 4   onehotencoder__x0_P  76050 non-null  float64\n",
      " 5   onehotencoder__x0_S  76050 non-null  float64\n",
      " 6   onehotencoder__x0_U  76050 non-null  float64\n",
      " 7   onehotencoder__x1_C  76050 non-null  float64\n",
      " 8   onehotencoder__x1_M  76050 non-null  float64\n",
      " 9   onehotencoder__x1_N  76050 non-null  float64\n",
      " 10  onehotencoder__x1_O  76050 non-null  float64\n",
      " 11  onehotencoder__x1_P  76050 non-null  float64\n",
      " 12  onehotencoder__x1_S  76050 non-null  float64\n",
      " 13  onehotencoder__x1_U  76050 non-null  float64\n",
      " 14  SEX                  76050 non-null  float64\n",
      " 15  MARITAL              76050 non-null  float64\n",
      " 16  FAGE                 76050 non-null  float64\n",
      " 17  GAINED               76050 non-null  float64\n",
      " 18  VISITS               76050 non-null  float64\n",
      " 19  MAGE                 76050 non-null  float64\n",
      " 20  FEDUC                76050 non-null  float64\n",
      " 21  MEDUC                76050 non-null  float64\n",
      " 22  TOTALP               76050 non-null  float64\n",
      " 23  BDEAD                76050 non-null  float64\n",
      " 24  TERMS                76050 non-null  float64\n",
      " 25  LOUTCOME             76050 non-null  float64\n",
      " 26  WEEKS                76050 non-null  float64\n",
      " 27  RACEMOM              76050 non-null  float64\n",
      " 28  RACEDAD              76050 non-null  float64\n",
      " 29  CIGNUM               76050 non-null  float64\n",
      " 30  DRINKNUM             76050 non-null  float64\n",
      " 31  ANEMIA               76050 non-null  float64\n",
      " 32  CARDIAC              76050 non-null  float64\n",
      " 33  ACLUNG               76050 non-null  float64\n",
      " 34  DIABETES             76050 non-null  float64\n",
      " 35  HERPES               76050 non-null  float64\n",
      " 36  HYDRAM               76050 non-null  float64\n",
      " 37  HEMOGLOB             76050 non-null  float64\n",
      " 38  HYPERCH              76050 non-null  float64\n",
      " 39  HYPERPR              76050 non-null  float64\n",
      " 40  ECLAMP               76050 non-null  float64\n",
      " 41  CERVIX               76050 non-null  float64\n",
      " 42  PINFANT              76050 non-null  float64\n",
      " 43  PRETERM              76050 non-null  float64\n",
      " 44  RENAL                76050 non-null  float64\n",
      " 45  RHSEN                76050 non-null  float64\n",
      " 46  UTERINE              76050 non-null  float64\n",
      "dtypes: float64(47)\n",
      "memory usage: 27.3 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 48 entries, onehotencoder__x0_C to BWEIGHT\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   BWEIGHT  48 non-null     float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 1.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BWEIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>onehotencoder__x0_C</th>\n",
       "      <td>-0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onehotencoder__x0_M</th>\n",
       "      <td>0.002062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onehotencoder__x0_N</th>\n",
       "      <td>-0.002872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onehotencoder__x0_O</th>\n",
       "      <td>0.005264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onehotencoder__x0_P</th>\n",
       "      <td>-0.000648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onehotencoder__x0_S</th>\n",
       "      <td>0.000798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onehotencoder__x0_U</th>\n",
       "      <td>0.004148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onehotencoder__x1_C</th>\n",
       "      <td>0.000511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onehotencoder__x1_M</th>\n",
       "      <td>0.000696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onehotencoder__x1_N</th>\n",
       "      <td>-0.006962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onehotencoder__x1_O</th>\n",
       "      <td>0.006191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onehotencoder__x1_P</th>\n",
       "      <td>0.004107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onehotencoder__x1_S</th>\n",
       "      <td>0.008514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onehotencoder__x1_U</th>\n",
       "      <td>0.004371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEX</th>\n",
       "      <td>0.001515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARITAL</th>\n",
       "      <td>-0.001298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAGE</th>\n",
       "      <td>-0.000429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAINED</th>\n",
       "      <td>-0.008894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VISITS</th>\n",
       "      <td>-0.005204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAGE</th>\n",
       "      <td>-0.006278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEDUC</th>\n",
       "      <td>-0.005683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEDUC</th>\n",
       "      <td>-0.003474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTALP</th>\n",
       "      <td>-0.007463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDEAD</th>\n",
       "      <td>-0.007951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TERMS</th>\n",
       "      <td>-0.008055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOUTCOME</th>\n",
       "      <td>0.003080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEEKS</th>\n",
       "      <td>-0.000945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RACEMOM</th>\n",
       "      <td>0.005348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RACEDAD</th>\n",
       "      <td>0.005357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CIGNUM</th>\n",
       "      <td>-0.000615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRINKNUM</th>\n",
       "      <td>-0.001095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANEMIA</th>\n",
       "      <td>-0.003266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARDIAC</th>\n",
       "      <td>0.011286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACLUNG</th>\n",
       "      <td>-0.005537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIABETES</th>\n",
       "      <td>-0.003417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HERPES</th>\n",
       "      <td>-0.006062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HYDRAM</th>\n",
       "      <td>-0.007007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEMOGLOB</th>\n",
       "      <td>-0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HYPERCH</th>\n",
       "      <td>0.001047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HYPERPR</th>\n",
       "      <td>-0.002619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECLAMP</th>\n",
       "      <td>-0.000870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CERVIX</th>\n",
       "      <td>0.010087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PINFANT</th>\n",
       "      <td>-0.004799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRETERM</th>\n",
       "      <td>-0.003569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RENAL</th>\n",
       "      <td>0.002545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RHSEN</th>\n",
       "      <td>0.001851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UTERINE</th>\n",
       "      <td>-0.004468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      BWEIGHT\n",
       "onehotencoder__x0_C -0.000085\n",
       "onehotencoder__x0_M  0.002062\n",
       "onehotencoder__x0_N -0.002872\n",
       "onehotencoder__x0_O  0.005264\n",
       "onehotencoder__x0_P -0.000648\n",
       "onehotencoder__x0_S  0.000798\n",
       "onehotencoder__x0_U  0.004148\n",
       "onehotencoder__x1_C  0.000511\n",
       "onehotencoder__x1_M  0.000696\n",
       "onehotencoder__x1_N -0.006962\n",
       "onehotencoder__x1_O  0.006191\n",
       "onehotencoder__x1_P  0.004107\n",
       "onehotencoder__x1_S  0.008514\n",
       "onehotencoder__x1_U  0.004371\n",
       "SEX                  0.001515\n",
       "MARITAL             -0.001298\n",
       "FAGE                -0.000429\n",
       "GAINED              -0.008894\n",
       "VISITS              -0.005204\n",
       "MAGE                -0.006278\n",
       "FEDUC               -0.005683\n",
       "MEDUC               -0.003474\n",
       "TOTALP              -0.007463\n",
       "BDEAD               -0.007951\n",
       "TERMS               -0.008055\n",
       "LOUTCOME             0.003080\n",
       "WEEKS               -0.000945\n",
       "RACEMOM              0.005348\n",
       "RACEDAD              0.005357\n",
       "CIGNUM              -0.000615\n",
       "DRINKNUM            -0.001095\n",
       "ANEMIA              -0.003266\n",
       "CARDIAC              0.011286\n",
       "ACLUNG              -0.005537\n",
       "DIABETES            -0.003417\n",
       "HERPES              -0.006062\n",
       "HYDRAM              -0.007007\n",
       "HEMOGLOB            -0.000262\n",
       "HYPERCH              0.001047\n",
       "HYPERPR             -0.002619\n",
       "ECLAMP              -0.000870\n",
       "CERVIX               0.010087\n",
       "PINFANT             -0.004799\n",
       "PRETERM             -0.003569\n",
       "RENAL                0.002545\n",
       "RHSEN                0.001851\n",
       "UTERINE             -0.004468"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ohe_imputed['BWEIGHT'] = y_train\n",
    "corr_df = X_train_ohe_imputed.corr(method='pearson')[('BWEIGHT')]\n",
    "corr_df = corr_df.to_frame()\n",
    "X_train_ohe_imputed.drop(['BWEIGHT'], axis=1, inplace=True)\n",
    "X_train_ohe_imputed.info()\n",
    "\n",
    "#corr_df['Absolute_corr_score'] = abs(corr_df['corr_score'])\n",
    "#corr_df.sort_values(by=['Absolute_corr_score'], ascending=False, inplace=True)\n",
    "#corr_df.drop(['Absolute_corr_score'], axis=1, inplace=True )\n",
    "corr_df.info()\n",
    "corr_df.head(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20 entries, 26 to 46\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   variable    20 non-null     object \n",
      " 1   corr_score  20 non-null     float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 480.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>corr_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>WEEKS</td>\n",
       "      <td>0.565254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GAINED</td>\n",
       "      <td>0.174466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>VISITS</td>\n",
       "      <td>0.129247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>HYPERPR</td>\n",
       "      <td>-0.111375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MARITAL</td>\n",
       "      <td>-0.106297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variable  corr_score\n",
       "26    WEEKS    0.565254\n",
       "17   GAINED    0.174466\n",
       "18   VISITS    0.129247\n",
       "39  HYPERPR   -0.111375\n",
       "15  MARITAL   -0.106297"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top20_df = top20_df_tmp.iloc[:20]\n",
    "top20_df.info()\n",
    "top20_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 highly correlated variables with respect to the target variable :\n",
      "  ['WEEKS' 'GAINED' 'VISITS' 'HYPERPR' 'MARITAL' 'SEX' 'CIGNUM' 'RACEDAD'\n",
      " 'RACEMOM' 'PRETERM' 'CERVIX' 'MAGE' 'PINFANT' 'ECLAMP' 'MEDUC' 'FAGE'\n",
      " 'FEDUC' 'HYDRAM' 'HYPERCH' 'UTERINE'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Top 20 highly correlated variables with respect to the target variable :\\n ',top20_df['variable'].unique(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 7: \n",
    "Given the X_train_ohe_imputed (as Pandas dataframe from task 5) and and top20_df (as Pandas Dataframe from Task 6) having 2 columns {variable_name,corr_score} similar to the one you computed in Task 6:\n",
    "* Please save as X_train_t20 keeping only the columns listed in the top20_df dataframe.\n",
    "* Repeat the process for X_test_ohe (obtained from task 4), and save it as X_test_t20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76050 entries, 0 to 76049\n",
      "Data columns (total 20 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SEX      76050 non-null  float64\n",
      " 1   MARITAL  76050 non-null  float64\n",
      " 2   FAGE     76050 non-null  float64\n",
      " 3   GAINED   76050 non-null  float64\n",
      " 4   VISITS   76050 non-null  float64\n",
      " 5   MAGE     76050 non-null  float64\n",
      " 6   FEDUC    76050 non-null  float64\n",
      " 7   MEDUC    76050 non-null  float64\n",
      " 8   WEEKS    76050 non-null  float64\n",
      " 9   RACEMOM  76050 non-null  float64\n",
      " 10  RACEDAD  76050 non-null  float64\n",
      " 11  CIGNUM   76050 non-null  float64\n",
      " 12  HYDRAM   76050 non-null  float64\n",
      " 13  HYPERCH  76050 non-null  float64\n",
      " 14  HYPERPR  76050 non-null  float64\n",
      " 15  ECLAMP   76050 non-null  float64\n",
      " 16  CERVIX   76050 non-null  float64\n",
      " 17  PINFANT  76050 non-null  float64\n",
      " 18  PRETERM  76050 non-null  float64\n",
      " 19  UTERINE  76050 non-null  float64\n",
      "dtypes: float64(20)\n",
      "memory usage: 11.6 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25350 entries, 0 to 25349\n",
      "Data columns (total 20 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SEX      25350 non-null  float64\n",
      " 1   MARITAL  25350 non-null  float64\n",
      " 2   FAGE     25350 non-null  float64\n",
      " 3   GAINED   25350 non-null  float64\n",
      " 4   VISITS   25350 non-null  float64\n",
      " 5   MAGE     25350 non-null  float64\n",
      " 6   FEDUC    25350 non-null  float64\n",
      " 7   MEDUC    25350 non-null  float64\n",
      " 8   WEEKS    25350 non-null  float64\n",
      " 9   RACEMOM  25350 non-null  float64\n",
      " 10  RACEDAD  25350 non-null  float64\n",
      " 11  CIGNUM   25350 non-null  float64\n",
      " 12  HYDRAM   25350 non-null  float64\n",
      " 13  HYPERCH  25350 non-null  float64\n",
      " 14  HYPERPR  25350 non-null  float64\n",
      " 15  ECLAMP   25350 non-null  float64\n",
      " 16  CERVIX   25350 non-null  float64\n",
      " 17  PINFANT  25350 non-null  float64\n",
      " 18  PRETERM  25350 non-null  float64\n",
      " 19  UTERINE  25350 non-null  float64\n",
      "dtypes: float64(20)\n",
      "memory usage: 3.9 MB\n"
     ]
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "new_columns = top20_df['variable'].unique()\n",
    "\n",
    "X_train_t20 = X_train_ohe_imputed[X_train_ohe_imputed.columns[X_train_ohe_imputed.columns.isin(new_columns)]]\n",
    "X_train_t20.info()\n",
    "\n",
    "#X_test_ohe - replacing missing values with mean of the columns\n",
    "X_test_ohe_imputed  = X_test_ohe.copy()\n",
    "for i in X_test_ohe_imputed.columns:\n",
    "    values = X_test_ohe_imputed[i].mean()\n",
    "    X_test_ohe_imputed[i].fillna(value=values, inplace=True)\n",
    "    \n",
    "\n",
    "X_test_t20 = X_test_ohe_imputed[X_test_ohe_imputed.columns[X_test_ohe_imputed.columns.isin(new_columns)]]\n",
    "X_test_t20.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 8: \n",
    "* Apply min-max scaling on the training dataset (X_train_t20 obtained from Task 7). Save the result as X_train_scaled_mm.\n",
    "* Then scale the test dataset (X_test_t20 obtained from Task 7) based on the metrics you obtain when you scale the training dataset. Save the result as X_test_scaled_mm.\n",
    "* PLEASE DO NOT SCALE y_train and y_test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76050 entries, 0 to 76049\n",
      "Data columns (total 20 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SEX      76050 non-null  float64\n",
      " 1   MARITAL  76050 non-null  float64\n",
      " 2   FAGE     76050 non-null  float64\n",
      " 3   GAINED   76050 non-null  float64\n",
      " 4   VISITS   76050 non-null  float64\n",
      " 5   MAGE     76050 non-null  float64\n",
      " 6   FEDUC    76050 non-null  float64\n",
      " 7   MEDUC    76050 non-null  float64\n",
      " 8   WEEKS    76050 non-null  float64\n",
      " 9   RACEMOM  76050 non-null  float64\n",
      " 10  RACEDAD  76050 non-null  float64\n",
      " 11  CIGNUM   76050 non-null  float64\n",
      " 12  HYDRAM   76050 non-null  float64\n",
      " 13  HYPERCH  76050 non-null  float64\n",
      " 14  HYPERPR  76050 non-null  float64\n",
      " 15  ECLAMP   76050 non-null  float64\n",
      " 16  CERVIX   76050 non-null  float64\n",
      " 17  PINFANT  76050 non-null  float64\n",
      " 18  PRETERM  76050 non-null  float64\n",
      " 19  UTERINE  76050 non-null  float64\n",
      "dtypes: float64(20)\n",
      "memory usage: 11.6 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25350 entries, 0 to 25349\n",
      "Data columns (total 20 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SEX      25350 non-null  float64\n",
      " 1   MARITAL  25350 non-null  float64\n",
      " 2   FAGE     25350 non-null  float64\n",
      " 3   GAINED   25350 non-null  float64\n",
      " 4   VISITS   25350 non-null  float64\n",
      " 5   MAGE     25350 non-null  float64\n",
      " 6   FEDUC    25350 non-null  float64\n",
      " 7   MEDUC    25350 non-null  float64\n",
      " 8   WEEKS    25350 non-null  float64\n",
      " 9   RACEMOM  25350 non-null  float64\n",
      " 10  RACEDAD  25350 non-null  float64\n",
      " 11  CIGNUM   25350 non-null  float64\n",
      " 12  HYDRAM   25350 non-null  float64\n",
      " 13  HYPERCH  25350 non-null  float64\n",
      " 14  HYPERPR  25350 non-null  float64\n",
      " 15  ECLAMP   25350 non-null  float64\n",
      " 16  CERVIX   25350 non-null  float64\n",
      " 17  PINFANT  25350 non-null  float64\n",
      " 18  PRETERM  25350 non-null  float64\n",
      " 19  UTERINE  25350 non-null  float64\n",
      "dtypes: float64(20)\n",
      "memory usage: 3.9 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>FAGE</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>MEDUC</th>\n",
       "      <th>WEEKS</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>CIGNUM</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>HYPERPR</th>\n",
       "      <th>ECLAMP</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEX  MARITAL  FAGE  GAINED  VISITS  MAGE  FEDUC  MEDUC  WEEKS  RACEMOM  \\\n",
       "0  2.0      1.0  30.0    33.0    16.0  29.0   16.0   17.0   39.0      1.0   \n",
       "1  2.0      1.0  23.0    20.0    10.0  22.0   12.0   15.0   39.0      2.0   \n",
       "2  1.0      2.0  24.0    34.0    12.0  21.0   10.0   14.0   38.0      2.0   \n",
       "3  2.0      1.0  32.0    16.0    15.0  28.0   12.0   13.0   39.0      1.0   \n",
       "4  2.0      1.0  26.0    30.0     7.0  30.0   16.0   16.0   39.0      1.0   \n",
       "\n",
       "   RACEDAD  CIGNUM  HYDRAM  HYPERCH  HYPERPR  ECLAMP  CERVIX  PINFANT  \\\n",
       "0      1.0     0.0     0.0      0.0      0.0     0.0     0.0      0.0   \n",
       "1      2.0     0.0     0.0      1.0      0.0     0.0     0.0      0.0   \n",
       "2      2.0     0.0     0.0      0.0      0.0     0.0     0.0      0.0   \n",
       "3      1.0     0.0     0.0      0.0      0.0     0.0     0.0      0.0   \n",
       "4      1.0     0.0     0.0      0.0      0.0     0.0     0.0      0.0   \n",
       "\n",
       "   PRETERM  UTERINE  \n",
       "0      0.0      0.0  \n",
       "1      0.0      0.0  \n",
       "2      0.0      0.0  \n",
       "3      0.0      0.0  \n",
       "4      0.0      0.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "#scaling X_train_t20\n",
    "X_trained_scaled_mm = X_train_t20.copy() \n",
    "\n",
    "for i in X_trained_scaled_mm.columns:\n",
    "    min_value = X_trained_scaled_mm[i].min() \n",
    "    max_value = X_trained_scaled_mm[i].max() \n",
    "    X_trained_scaled_mm[i] = (X_trained_scaled_mm[i] - min_value)/(max_value-min_value)\n",
    "    \n",
    "X_trained_scaled_mm.info()\n",
    "\n",
    "\n",
    "#check once????????????????????????????????????\n",
    "#scaling X_test_t20\n",
    "X_test_scaled_mm = X_test_t20.copy() \n",
    "\n",
    "for i in X_trained_scaled_mm.columns:\n",
    "    min_value = X_trained_scaled_mm[i].min() \n",
    "    max_value = X_trained_scaled_mm[i].max() \n",
    "    X_test_scaled_mm[i] = (X_test_scaled_mm[i] - min_value)/(max_value-min_value)\n",
    "    \n",
    "X_test_scaled_mm.info()\n",
    "X_test_scaled_mm.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 9: \n",
    "* Apply standardization (i.e., normalization) scaling on the training dataset (X_train_t20 obtained from Task 7). Save the result as X_train_scaled_std.\n",
    "* Then scale the test dataset (X_test_t20 obtained from Task 7) based on the metrics you obtain when you scale the training dataset. Save the result as X_test_scaled_std.\n",
    "* PLEASE DO NOT SCALE y_train and y_test.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76050 entries, 0 to 76049\n",
      "Data columns (total 20 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SEX      76050 non-null  float64\n",
      " 1   MARITAL  76050 non-null  float64\n",
      " 2   FAGE     76050 non-null  float64\n",
      " 3   GAINED   76050 non-null  float64\n",
      " 4   VISITS   76050 non-null  float64\n",
      " 5   MAGE     76050 non-null  float64\n",
      " 6   FEDUC    76050 non-null  float64\n",
      " 7   MEDUC    76050 non-null  float64\n",
      " 8   WEEKS    76050 non-null  float64\n",
      " 9   RACEMOM  76050 non-null  float64\n",
      " 10  RACEDAD  76050 non-null  float64\n",
      " 11  CIGNUM   76050 non-null  float64\n",
      " 12  HYDRAM   76050 non-null  float64\n",
      " 13  HYPERCH  76050 non-null  float64\n",
      " 14  HYPERPR  76050 non-null  float64\n",
      " 15  ECLAMP   76050 non-null  float64\n",
      " 16  CERVIX   76050 non-null  float64\n",
      " 17  PINFANT  76050 non-null  float64\n",
      " 18  PRETERM  76050 non-null  float64\n",
      " 19  UTERINE  76050 non-null  float64\n",
      "dtypes: float64(20)\n",
      "memory usage: 11.6 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25350 entries, 0 to 25349\n",
      "Data columns (total 20 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   SEX      25350 non-null  float64\n",
      " 1   MARITAL  25350 non-null  float64\n",
      " 2   FAGE     25350 non-null  float64\n",
      " 3   GAINED   25350 non-null  float64\n",
      " 4   VISITS   25350 non-null  float64\n",
      " 5   MAGE     25350 non-null  float64\n",
      " 6   FEDUC    25350 non-null  float64\n",
      " 7   MEDUC    25350 non-null  float64\n",
      " 8   WEEKS    25350 non-null  float64\n",
      " 9   RACEMOM  25350 non-null  float64\n",
      " 10  RACEDAD  25350 non-null  float64\n",
      " 11  CIGNUM   25350 non-null  float64\n",
      " 12  HYDRAM   25350 non-null  float64\n",
      " 13  HYPERCH  25350 non-null  float64\n",
      " 14  HYPERPR  25350 non-null  float64\n",
      " 15  ECLAMP   25350 non-null  float64\n",
      " 16  CERVIX   25350 non-null  float64\n",
      " 17  PINFANT  25350 non-null  float64\n",
      " 18  PRETERM  25350 non-null  float64\n",
      " 19  UTERINE  25350 non-null  float64\n",
      "dtypes: float64(20)\n",
      "memory usage: 3.9 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>FAGE</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>MEDUC</th>\n",
       "      <th>WEEKS</th>\n",
       "      <th>RACEMOM</th>\n",
       "      <th>RACEDAD</th>\n",
       "      <th>CIGNUM</th>\n",
       "      <th>HYDRAM</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>HYPERPR</th>\n",
       "      <th>ECLAMP</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>UTERINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.033928</td>\n",
       "      <td>-0.660549</td>\n",
       "      <td>-0.031093</td>\n",
       "      <td>0.190672</td>\n",
       "      <td>0.967502</td>\n",
       "      <td>0.212669</td>\n",
       "      <td>1.045799</td>\n",
       "      <td>1.268836</td>\n",
       "      <td>0.105077</td>\n",
       "      <td>-0.338950</td>\n",
       "      <td>-0.354573</td>\n",
       "      <td>-0.244465</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>-0.117632</td>\n",
       "      <td>-0.22485</td>\n",
       "      <td>-0.064799</td>\n",
       "      <td>-0.05902</td>\n",
       "      <td>-0.072071</td>\n",
       "      <td>-0.094842</td>\n",
       "      <td>-0.060351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.033928</td>\n",
       "      <td>-0.660549</td>\n",
       "      <td>-1.064118</td>\n",
       "      <td>-0.759502</td>\n",
       "      <td>-0.652903</td>\n",
       "      <td>-0.964881</td>\n",
       "      <td>-0.319270</td>\n",
       "      <td>0.589526</td>\n",
       "      <td>0.105077</td>\n",
       "      <td>0.439134</td>\n",
       "      <td>0.459891</td>\n",
       "      <td>-0.244465</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>8.500767</td>\n",
       "      <td>-0.22485</td>\n",
       "      <td>-0.064799</td>\n",
       "      <td>-0.05902</td>\n",
       "      <td>-0.072071</td>\n",
       "      <td>-0.094842</td>\n",
       "      <td>-0.060351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.967147</td>\n",
       "      <td>1.513833</td>\n",
       "      <td>-0.916543</td>\n",
       "      <td>0.263762</td>\n",
       "      <td>-0.112768</td>\n",
       "      <td>-1.133102</td>\n",
       "      <td>-1.001804</td>\n",
       "      <td>0.249871</td>\n",
       "      <td>-0.295180</td>\n",
       "      <td>0.439134</td>\n",
       "      <td>0.459891</td>\n",
       "      <td>-0.244465</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>-0.117632</td>\n",
       "      <td>-0.22485</td>\n",
       "      <td>-0.064799</td>\n",
       "      <td>-0.05902</td>\n",
       "      <td>-0.072071</td>\n",
       "      <td>-0.094842</td>\n",
       "      <td>-0.060351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.033928</td>\n",
       "      <td>-0.660549</td>\n",
       "      <td>0.264057</td>\n",
       "      <td>-1.051864</td>\n",
       "      <td>0.697435</td>\n",
       "      <td>0.044448</td>\n",
       "      <td>-0.319270</td>\n",
       "      <td>-0.089784</td>\n",
       "      <td>0.105077</td>\n",
       "      <td>-0.338950</td>\n",
       "      <td>-0.354573</td>\n",
       "      <td>-0.244465</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>-0.117632</td>\n",
       "      <td>-0.22485</td>\n",
       "      <td>-0.064799</td>\n",
       "      <td>-0.05902</td>\n",
       "      <td>-0.072071</td>\n",
       "      <td>-0.094842</td>\n",
       "      <td>-0.060351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.033928</td>\n",
       "      <td>-0.660549</td>\n",
       "      <td>-0.621393</td>\n",
       "      <td>-0.028599</td>\n",
       "      <td>-1.463105</td>\n",
       "      <td>0.380890</td>\n",
       "      <td>1.045799</td>\n",
       "      <td>0.929181</td>\n",
       "      <td>0.105077</td>\n",
       "      <td>-0.338950</td>\n",
       "      <td>-0.354573</td>\n",
       "      <td>-0.244465</td>\n",
       "      <td>-0.120696</td>\n",
       "      <td>-0.117632</td>\n",
       "      <td>-0.22485</td>\n",
       "      <td>-0.064799</td>\n",
       "      <td>-0.05902</td>\n",
       "      <td>-0.072071</td>\n",
       "      <td>-0.094842</td>\n",
       "      <td>-0.060351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SEX   MARITAL      FAGE    GAINED    VISITS      MAGE     FEDUC  \\\n",
       "0  1.033928 -0.660549 -0.031093  0.190672  0.967502  0.212669  1.045799   \n",
       "1  1.033928 -0.660549 -1.064118 -0.759502 -0.652903 -0.964881 -0.319270   \n",
       "2 -0.967147  1.513833 -0.916543  0.263762 -0.112768 -1.133102 -1.001804   \n",
       "3  1.033928 -0.660549  0.264057 -1.051864  0.697435  0.044448 -0.319270   \n",
       "4  1.033928 -0.660549 -0.621393 -0.028599 -1.463105  0.380890  1.045799   \n",
       "\n",
       "      MEDUC     WEEKS   RACEMOM   RACEDAD    CIGNUM    HYDRAM   HYPERCH  \\\n",
       "0  1.268836  0.105077 -0.338950 -0.354573 -0.244465 -0.120696 -0.117632   \n",
       "1  0.589526  0.105077  0.439134  0.459891 -0.244465 -0.120696  8.500767   \n",
       "2  0.249871 -0.295180  0.439134  0.459891 -0.244465 -0.120696 -0.117632   \n",
       "3 -0.089784  0.105077 -0.338950 -0.354573 -0.244465 -0.120696 -0.117632   \n",
       "4  0.929181  0.105077 -0.338950 -0.354573 -0.244465 -0.120696 -0.117632   \n",
       "\n",
       "   HYPERPR    ECLAMP   CERVIX   PINFANT   PRETERM   UTERINE  \n",
       "0 -0.22485 -0.064799 -0.05902 -0.072071 -0.094842 -0.060351  \n",
       "1 -0.22485 -0.064799 -0.05902 -0.072071 -0.094842 -0.060351  \n",
       "2 -0.22485 -0.064799 -0.05902 -0.072071 -0.094842 -0.060351  \n",
       "3 -0.22485 -0.064799 -0.05902 -0.072071 -0.094842 -0.060351  \n",
       "4 -0.22485 -0.064799 -0.05902 -0.072071 -0.094842 -0.060351  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "#X_train_scaled_std - X_train_20\n",
    "#X_test_scaled_std - X_test_20\n",
    "\n",
    "#scaling X_train_t20 using standardization\n",
    "X_train_scaled_std = X_train_t20.copy() \n",
    "\n",
    "for i in X_train_scaled_std.columns:\n",
    "    mean = X_train_scaled_std[i].mean() \n",
    "    std = X_train_scaled_std[i].std()\n",
    "    X_train_scaled_std[i] = (X_train_scaled_std[i] - mean)/std\n",
    "    \n",
    "X_train_scaled_std.info()\n",
    "#X_train_scaled_std.head()\n",
    "\n",
    "\n",
    "#check once????????????????????????????????????\n",
    "#scaling X_test_t20 using standardization\n",
    "X_test_scaled_std = X_test_t20.copy() \n",
    "\n",
    "for i in X_test_scaled_std.columns:\n",
    "    mean = X_test_scaled_std[i].mean() \n",
    "    std = X_test_scaled_std[i].std()\n",
    "    X_test_scaled_std[i] = (X_test_scaled_std[i] - mean)/std    \n",
    "X_test_scaled_std.info()\n",
    "X_test_scaled_std.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 10: \n",
    "Given the (X_train_scaled_std, y_train) pairs denoting input matrix and output vector respectively: complete the three function definitions and demonstrate the functionalities of each by calling them with appropriate arguments as instructed below:\n",
    "* **linear_regression_closed_form_training** : It fits a linear regression model using the closed-form solution to obtain the coefficients, beta's, as a numpy array of m+1 values (Please recall class lecture), where *m* is the number of variables kept in X_train (the first argument to the function). Please measure the cpu_time needed during the training step. cpu_time is not equal to the wall_time. So, use time.perf_counter() for an accurate measurement. Documentation on this function can be found here: https://docs.python.org/3/library/time.html . Finally, the function returns betas (i.e., the m+1 beta values) and the  cpu_time.\n",
    "* **linear_regression_closed_form_predict**: It takes a list of m+1 beta values (i.e., betas returned from the corresponding training function, and X_test (containing test samples each having *m* input variables). Now, using the provided beta values, predict each of the test samples provided, and let's name your prediction \"y_pred\". Return y_pred from the function.\n",
    "* **RMSE**: It takes two lists: y_test, y_pred, where the first list represents ground truth (i.e., actual) target values for the given samples, and the second list represents a corresponding predicted values for exactly same number of samples in y_test. Compute and return the Root Mean Squared Error (RMSE) of the prediction. \n",
    "\n",
    "* PLEASE DO NOT USE ANY LIBRARY FUNCTION THAT DOES THE LINEAR REGRESSION.\n",
    "* Now, call linear_regression_closed_form_training() function providing X_train_scaled_std, y_train obtained from Task 9, and save the returned results as betas_closed_form,cpu_time_closed_form.\n",
    "* Print betas_closed_form, cpu_time_closed_form\n",
    "* Call linear_regression_closed_form_predict() function providing betas_closed_form,X_test_scaled_std obtained in Task 9. Save the returned result as y_pred.\n",
    "* Call RMSE() function providing y_test and y_pred. Save returned result as rmse_closed_form.\n",
    "* Print rmse_closed_form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from time import perf_counter\n",
    "\n",
    "def linear_regression_closed_form_training(X_train, y_train):\n",
    "    cpu_time = 0\n",
    "    betas = []\n",
    "    #@TODO: Your code goes here\n",
    "    starting_time = perf_counter()\n",
    "    \n",
    "    #do we get beta 0???????????????????????\n",
    "    #we have to get 21 betas right?????????????????????\n",
    "    betas = np.dot(np.linalg.inv(np.dot(X_train.T, X_train)), np.dot(X_train.T, y_train)) \n",
    "    \n",
    "    ending_time = perf_counter()\n",
    "    cpu_time = ending_time - starting_time\n",
    "    \n",
    "    return betas,cpu_time\n",
    "\n",
    "\n",
    "def linear_regression_closed_form_predict(betas, X_test):\n",
    "    y_pred = []\n",
    "    \n",
    "    #@TODO: Your code goes here\n",
    "    #X_test = np.append(X_test, np.ones((X_test.shape[0],1)), axis=1)\n",
    "    y_pred = np.dot(X_test, betas)\n",
    "       \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def RMSE(y_test, y_pred):\n",
    "    rmse = -1\n",
    "    \n",
    "    #@TODO: Your code goes here\n",
    "    sum_val = 0\n",
    "    \n",
    "    #@TODO: Your code goes here\n",
    "    n = len(y_test)\n",
    "    for i in range(len(y_test)):\n",
    "        sum_val  = sum_val + (y_test[i]-y_pred[i])**2\n",
    "    rmse = np.sqrt(sum_val/n)\n",
    "       \n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1296124  -0.07634839  0.00921889  0.16451734  0.03403537  0.10283524\n",
      " -0.01519343 -0.01662484  0.71519793 -0.04475454 -0.05847479 -0.09253393\n",
      " -0.04398413 -0.0263846  -0.08264326 -0.03912318 -0.02739167  0.07233297\n",
      " -0.03880437 -0.01920369  7.25699786]\n",
      "cpu_time  0.1848219000003155\n"
     ]
    }
   ],
   "source": [
    "#X_train_scaled_std, y_train\n",
    "X_train_scaled_std['bias_column'] = 1\n",
    "betas, cpu_time = linear_regression_closed_form_training(X_train_scaled_std, y_train)\n",
    "print(betas)\n",
    "print('cpu_time ',cpu_time)\n",
    "\n",
    "X_test_scaled_std['bias_column'] = 1\n",
    "y_pred = linear_regression_closed_form_predict(betas, X_test_scaled_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25350\n",
      "y_pred  7.386765850017787\n",
      "y_test  7.1875\n",
      "y_train  9.0\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred))\n",
    "print('y_pred ',y_pred[0])\n",
    "\n",
    "y_test1 = y_test.to_numpy()\n",
    "print('y_test ',y_test1[0])\n",
    "\n",
    "y_train1 = y_train.to_numpy()\n",
    "print('y_train ',y_train1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.97183205, -0.66061914,  0.86159098,  1.45316379,\n",
       "         0.95157943,  0.71515312, -0.31585834, -0.08667919, -0.29311089,\n",
       "        -0.33869071, -0.35270066, -0.24367964, -0.1230882 , -0.11832082,\n",
       "        -0.23104492, -0.06078935, -0.06197643, 13.03444062, -0.09441902,\n",
       "        -0.05823032,  1.        ],\n",
       "       [ 1.        ,  1.02594677,  1.51371159, -1.05712474,  1.45316379,\n",
       "         0.14891879, -1.29770383, -0.31585834,  0.59617702,  0.90338883,\n",
       "         0.42696515,  0.44671772, -0.24367964, -0.1230882 , -0.11832082,\n",
       "        -0.23104492, -0.06078935, -0.06197643, -0.07671882, -0.09441902,\n",
       "        -0.05823032,  1.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled_std1 = np.c_[np.ones(len(X_train_scaled_std),dtype='int64'),X_train_scaled_std]\n",
    "X_train_scaled_std1[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.04346298903701\n"
     ]
    }
   ],
   "source": [
    "#@TODO: Your code goes here\n",
    "rmse_closed_form = RMSE(y_test1, y_pred)\n",
    "print( rmse_closed_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 11: \n",
    "Given the (X_train_scaled_std, y_train) pairs denoting input matrix and output vector respectively: complete the three function definitions and demonstrate the functionalities of each by calling them with appropriate arguments as instructed below:\n",
    "* **linear_regression_gd_batch_training** : It fits a linear regression model using the batch gradient descent algorithm to obtain the coefficients, beta's, as a numpy array of m+1 values, where *m* is the number of variables kept in X_train (the first argument to the function). Please use the alpha (i.e, the learning rate) and nEpoch (number of epochs) parameters in your implementation of the gradient descent algorithm. Please measure the cpu_time needed during the training step. cpu_time is not equal to the wall_time. So, use time.perf_counter() for an accurate measurement. Documentation on this function can be found here: https://docs.python.org/3/library/time.html . Finally, the function returns betas (i.e., the m+1 beta values) and the  cpu_time.\n",
    "* **linear_regression_gd_batch_predict**: It takes a list of m+1 beta values (i.e., betas returned from the corresponding training function, and X_test (containing test samples each having *m* input variables). Now, using the provided beta values, predict each of the test samples provided, and let's name your prediction \"y_pred\". Return y_pred from the function. \n",
    "\n",
    "* PLEASE DO NOT USE ANY LIBRARY FUNCTION THAT DOES THE LINEAR REGRESSION.\n",
    "* Now, call linear_regression_gd_batch_training() function providing X_train_scaled_std, y_train obtained from Task 9, and alpha=0.01,nEpoch=1000, and save the returned results as betas_batch,cpu_time_batch.\n",
    "* Print betas_batch, cpu_time_batch\n",
    "* Call linear_regression_gd_batch_predict() function providing betas_batch,X_test_scaled_std obtained in Task 9. Save the returned result as y_pred.\n",
    "* Call RMSE() function providing y_test and y_pred. Save returned result as rmse_batch.\n",
    "* Print rmse_batch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_gd_batch_training(X_train,y_train, alpha, nEpoch):\n",
    "    import random\n",
    "    random.seed(554433)\n",
    "    from time import perf_counter\n",
    "    import numpy as np\n",
    "    betas = []\n",
    "    cpu_time = 0\n",
    "    #@TODO: Your code goes here\n",
    "    grad_value = \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #alpha=0.01,nEpoch=1000\n",
    "\n",
    "    return betas, cpu_time\n",
    "\n",
    "def linear_regression_gd_batch_predict(betas,X_test):\n",
    "    y_pred = []\n",
    "    #@TODO: Your code goes here\n",
    "    \n",
    "    \n",
    "    \n",
    "    return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "linear_regression_gd_batch_training(X_train_scaled_std, y_train, alpha=0.01,nEpoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 12:\n",
    "Given the (X_train_scaled_std, y_train) pairs denoting input matrix and output vector respectively: complete the three function definitions and demonstrate the functionalities of each by calling them with appropriate arguments as instructed below:\n",
    "* **linear_regression_gd_stochastic_training** : It fits a linear regression model using the stochastic gradient descent algorithm to obtain the coefficients, beta's, as a numpy array of m+1 values, where *m* is the number of variables kept in X_train (the first argument to the function). Please use the alpha (i.e, the learning rate), nEpoch (number of epochs), nIteration (number of iterations) parameters in your implementation of the gradient descent algorithm. Please measure the cpu_time needed during the training step. cpu_time is not equal to the wall_time. So, use time.perf_counter() for an accurate measurement. Documentation on this function can be found here: https://docs.python.org/3/library/time.html . Finally, the function returns betas (i.e., the m+1 beta values) and the  cpu_time.\n",
    "* **linear_regression_gd_stochastic_predict**: It takes a list of m+1 beta values (i.e., betas returned from the corresponding training function, and X_test (containing test samples each having *m* input variables). Now, using the provided beta values, predict each of the test samples provided, and let's name your prediction \"y_pred\". Return y_pred from the function. \n",
    "\n",
    "* PLEASE DO NOT USE ANY LIBRARY FUNCTION THAT DOES THE LINEAR REGRESSION.\n",
    "* Now, call linear_regression_gd_stochastic_training() function providing X_train_scaled_std, y_train obtained from Task 9, and alpha=0.01,nEpoch=50, nIteration=100 , and save the returned results as betas_stochastic,cpu_time_stochastic.\n",
    "* Print betas_stochastic, cpu_time_stochastic\n",
    "* Call linear_regression_gd_stochastic_predict() function providing betas_stochastic,X_test_scaled_std obtained in Task 9. Save the returned result as y_pred.\n",
    "* Call RMSE() function providing y_test and y_pred. Save returned result as rmse_stochastic.\n",
    "* Print rmse_stochastic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_gd_stochastic_training(X_train,y_train,alpha,nEpoch,nIteration):\n",
    "    import random\n",
    "    from time import perf_counter\n",
    "    import numpy as np\n",
    "    random.seed(554433)\n",
    "    betas = []\n",
    "    cpu_time = 0\n",
    "    #alpha=0.01,nEpoch=50, nIteration=100\n",
    "    ## YOUR CODE HERE ###\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return betas, cpu_time\n",
    "\n",
    "def linear_regression_gd_stochastic_predict(betas, X_test):\n",
    "\n",
    "    y_pred = []\n",
    "    ## YOUR CODE HERE ###\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return y_pred\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@TODO: Your code goes here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 13: \n",
    "Given the (X_train_scaled_std, y_train) pairs denoting input matrix and output vector respectively: complete the three function definitions and demonstrate the functionalities of each by calling them with appropriate arguments as instructed below:\n",
    "* **linear_regression_gd_minibatch_training** : It fits a linear regression model using the minibatch gradient descent algorithm to obtain the coefficients, beta's, as a numpy array of m+1 values, where *m* is the number of variables kept in X_train (the first argument to the function). Please use the alpha (i.e, the learning rate), nEpoch (number of epochs), nIteration (number of iterations), and batch_size parameters in your implementation of the gradient descent algorithm. Please measure the cpu_time needed during the training step. cpu_time is not equal to the wall_time. So, use time.perf_counter() for an accurate measurement. Documentation on this function can be found here: https://docs.python.org/3/library/time.html . Finally, the function returns betas (i.e., the m+1 beta values) and the  cpu_time.\n",
    "* **linear_regression_gd_minibatch_predict**: It takes a list of m+1 beta values (i.e., betas returned from the corresponding training function, and X_test (containing test samples each having *m* input variables). Now, using the provided beta values, predict each of the test samples provided, and let's name your prediction \"y_pred\". Return y_pred from the function. \n",
    "\n",
    "* PLEASE DO NOT USE ANY LIBRARY FUNCTION THAT DOES THE LINEAR REGRESSION.\n",
    "* Now, call linear_regression_gd_minibatch_training() function providing X_train_scaled_std, y_train obtained from Task 9, and alpha=0.001,nEpoch=50, nIteration=1000,batch_size=32, and save the returned results as betas_minibatch,cpu_time_minibatch.\n",
    "* Print betas_minibatch, cpu_time_minibatch\n",
    "* Call linear_regression_gd_minibatch_predict() function providing betas_minibatch,X_test_scaled_std obtained in Task 9. Save the returned result as y_pred.\n",
    "* Call RMSE() function providing y_test and y_pred. Save returned result as rmse_minibatch.\n",
    "* Print rmse_minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_gd_minibatch_training(X_train,y_train,alpha,nEpoch, nIteration, batch_size):\n",
    "    import random\n",
    "    from time import perf_counter\n",
    "    import numpy as np\n",
    "    random.seed(554433)\n",
    "\n",
    "    betas = []\n",
    "    cpu_time = 0\n",
    "    #alpha=0.001,nEpoch=50, nIteration=1000,batch_size=32\n",
    "    ## YOUR CODE HERE ###\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return betas,cpu_time\n",
    "\n",
    "def linear_regression_gd_minibatch_predict(betas,X_test):\n",
    "    y_pred = []\n",
    "    ## YOUR CODE HERE ###\n",
    "    \n",
    "    \n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 14:\n",
    "Given the 4 sets of results from the 4 experiments (from Tasks 10, 11, 12, 13) with closed form solution, batch gradient descent, stochastic gradient descent and mini-batch gradient descent, print a string from the set {\"closed-form\", \"batch-GD\", \"stochastic-GD\", \"minibatch-GD\"} that demonstrated the best predictive performance in terms of RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 15: \n",
    "Given the 4 sets of results from the 4 experiments (from Tasks 10, 11, 12, 13) with closed form solution, batch gradient descent, stochastic gradient descent and mini-batch gradient descent, print a string from the set {\"closed-form\", \"batch-GD\", \"stochastic-GD\", \"minibatch-GD\"} that demonstrated the least training cpu time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 16: \n",
    "Given the (X_train_scaled_std, y_train) pairs denoting input matrix and output vector respectively, \n",
    "* call your implementation of Task 12: stochastic gradient descent based linear regression for each of these learning rates: {0.0001, 0.001, 0.05, 0.01, 0.1, 1.0}\n",
    "    * Please use the nIteration (number of iterations), nEpoch (number of epoch) parameters in your implementation of the gradient descent algorithm.\n",
    "\n",
    "* For each of the linear regression model, using the computed beta values, predict the test samples provided in the \"X_test_scaled_std\" argument, and let's name your prediction \"y_pred\".\n",
    "* Compute Root Mean Squared Error (RMSE) of your prediction using the RMSE() function you defined in Task 10.\n",
    "* Finally, print the learning rate that shows the best test performance, and also print as a pandas dataframe named summary with 2 columns: {learning_rate, test_RMSE} containing RMSE's of the 6 linear regression models. Also, print the best performing learning rate.\n",
    "* PLEASE DO NOT USE ANY LIBRARY FUNCTION THAT DOES THE LINEAR REGRESSION.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 17:\n",
    "* Utilizing the best trained linear regression model (so far), predict the target for each of the samples in the judge_dataset.\n",
    "    * I believe you will not forget to do the following before call in the prediction algorithm:\n",
    "        - Save the ID values of the judge dataset into ID_judge and drop it from the judge dataframe.\n",
    "        - Perform onehot encoding using the same encoder you used to encode X_test (Task 4). \n",
    "        - keep only the same top 20 variables as you did in Task 7. \n",
    "        - scale the input variables based on the same metrics you used to scale the training dataset (Task 9). \n",
    "    * Now, call the prediction function of that model to obtain y_pred.\n",
    "    * Prepare and print as a pandas dataframe having columns: {ID, BWEIGHT}, where ID will the ID of the judge sample, and BWEIGHT is the corresponding y_pred value from your model prediction.\n",
    "* PLEASE DO NOT USE ANY LIBRARY FUNCTION THAT DOES THE LINEAR REGRESSION.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graduate Students only\n",
    "## Task 18:\n",
    "Bring your best model and submit your solution at https://www.kaggle.com/c/birth-weight-prediction\n",
    "Submit multiple entries. Demonstrate your effort by pushing yourself to improve your own score or beat other submissions (if any available) until the deadline and document your scores and list what changes you made in your submitted solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[7, 8]\n",
      "5\n",
      "[6, 7]\n",
      "4\n",
      "[5, 6]\n",
      "8\n",
      "[9, 10]\n",
      "5\n",
      "[6, 7]\n",
      "4\n",
      "[5, 6]\n",
      "7\n",
      "[8, 9]\n",
      "0\n",
      "[1, 2]\n",
      "2\n",
      "[3, 4]\n",
      "2\n",
      "[3, 4]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "l = [1,2,3,4,5,6,7,8,9,10]\n",
    "batch_size = 2\n",
    "for i in range(10):\n",
    "    index = random.randint(0, len(l)-batch_size)\n",
    "    print(index)\n",
    "    print(l[index:index+batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "print(l[0:len(l)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
